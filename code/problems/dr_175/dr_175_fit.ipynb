{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.linalg import lu\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "n_drugs = 175\n",
    "features_path = \"../../../DR_Data/epilepsy_signatures_nonbinarized_{}drugs.csv\".format(n_drugs)\n",
    "rewards_path = \"../../../DR_Data/rewards_cosine_{}drugs_18samples.csv\".format(n_drugs)\n",
    "\n",
    "features = pd.read_csv(features_path, index_col=0, header=0).values.T\n",
    "print(\"Loaded feature matrix: {}\".format(features.shape))\n",
    "print(\"max {} min {} mean {}\".format(features.max(), features.min(), features.mean()))\n",
    "print()\n",
    "\n",
    "rewards = pd.read_csv(rewards_path, header=0, index_col=0, names=[\"c{}\".format(i) for i in range(n_drugs)])\n",
    "rewards = rewards.to_numpy().T\n",
    "rewards.shape\n",
    "print(\"Loaded reward matrix: {}\".format(rewards.shape))\n",
    "print(\"max {} min {} mean {}\".format(rewards.max(), rewards.min(), rewards.mean()))\n",
    "print()\n",
    "\n",
    "plt.hist(np.mean(rewards, axis=1))\n",
    "\n",
    "means = np.mean(rewards, axis=1)\n",
    "print(\"MEAN: max {} min {} mean {}\".format(means.max(), means.min(), means.mean()))\n",
    "stds = np.std(rewards, axis=1)\n",
    "print(\"STD: max {} min {} mean {}\".format(stds.max(), stds.min(), stds.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "\n",
    "n_patients = rewards.shape[1]\n",
    "n_samples = n_drugs * n_patients\n",
    "\n",
    "# Whether to add the (binarized) patient id as an element of the feature vector\n",
    "# If patient_as_input is True, we fit a network to regress (drug_feature, patient) -> reward\n",
    "# where reward is the score associated to each drug,patient couple\n",
    "# If patient_as_input is False, we fit a network to regress (drug_feature) -> avg_reward\n",
    "# where avg_reward is the average (across patients) reward for each drug\n",
    "patient_as_input = False\n",
    "\n",
    "dim = features.shape[1] + (n_patients if patient_as_input else 0)\n",
    "\n",
    "X = np.zeros((n_samples, dim))  # network inputs (matrix of features)\n",
    "y = np.zeros(n_samples)  # network targets (vector of rewards)\n",
    "\n",
    "for k in range(n_drugs):\n",
    "    for p in range(n_patients):\n",
    "        phi = features[k, :]\n",
    "        if patient_as_input:\n",
    "            bin_p = np.zeros(n_patients)\n",
    "            bin_p[p] = 1\n",
    "            phi = np.concatenate([phi, bin_p])\n",
    "        idx = k*n_patients + p\n",
    "        X[idx, :] = phi\n",
    "        y[idx] = rewards[k,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(net, normalize=False):\n",
    "\n",
    "    # Build features\n",
    "    X_pred = X if patient_as_input else features\n",
    "\n",
    "    hidden_layer_sizes = list(net.hidden_layer_sizes)\n",
    "\n",
    "    layer_units = [X_pred.shape[1]] + hidden_layer_sizes + [1]\n",
    "    activations = [X_pred]\n",
    "    for i in range(net.n_layers_ - 1):\n",
    "        activations.append(np.empty((X_pred.shape[0], layer_units[i + 1])))\n",
    "\n",
    "    net._forward_pass(activations)\n",
    "    y_pred = activations[-1]\n",
    "    y_tgt = y if patient_as_input else np.mean(rewards, 1)\n",
    "    print(\"MSE (original):\", np.mean((y_pred.flatten() - y_tgt) ** 2))\n",
    "\n",
    "    # get weights\n",
    "    last_w = net.coefs_[-1]\n",
    "    bias = np.array(net.intercepts_[-1]).reshape((1, 1))\n",
    "    last_w = np.concatenate([last_w, bias])\n",
    "\n",
    "    # get last-layer features\n",
    "    last_feat = np.array(activations[-2], dtype=np.float32)\n",
    "    last_feat = np.concatenate([last_feat, np.ones((X_pred.shape[0], 1))], axis=1)\n",
    "\n",
    "    # get prediction\n",
    "    pred = last_feat.dot(last_w)\n",
    "    print(\"MSE (recomputed with last layer only):\", np.mean((pred.flatten() - y_tgt) ** 2))\n",
    "\n",
    "    # get feature matrix\n",
    "    d = hidden_layer_sizes[-1] + 1\n",
    "    print(\"d={0}\".format(d))\n",
    "    if patient_as_input:\n",
    "        phi = np.empty((n_patients, n_drugs, d), dtype=np.float32)\n",
    "        idx = 0\n",
    "        for p in range(n_patients):\n",
    "            for k in range(n_drugs):\n",
    "                phi[p, k, :] = last_feat[idx, :]\n",
    "                idx += 1\n",
    "        assert idx == last_feat.shape[0]\n",
    "    else:\n",
    "        phi = last_feat\n",
    "\n",
    "    # get param\n",
    "    theta = np.array(last_w, dtype=np.float32).squeeze()\n",
    "        \n",
    "    phi_norm = round(np.linalg.norm(phi, axis=2 if patient_as_input else 1).max(), 2)\n",
    "    print(\"phi max norm:\", phi_norm)\n",
    "    theta_norm = round(np.linalg.norm(theta), 2)\n",
    "    print(\"theta norm:\", theta_norm)\n",
    "\n",
    "    # check predictions\n",
    "    mu = phi.dot(theta)\n",
    "    targets = rewards.T if patient_as_input else np.mean(rewards, axis=1)\n",
    "    l2_dev = np.abs(targets - mu).flatten()**2\n",
    "    print(\"l2 deviation (mu): max {} min {} mean {}\".format(l2_dev.max(), l2_dev.min(), l2_dev.mean()))\n",
    "    l1_dev = np.abs(targets - mu).flatten()\n",
    "    print(\"l1 deviation (mu): max {} min {} mean {}\".format(l1_dev.max(), l1_dev.min(), l1_dev.mean()))\n",
    "    max_dev = round(l1_dev.max(),3)\n",
    "    print(\"mu: max {0} - min {1}\".format(mu.max(), mu.min()))\n",
    "    gap = np.max(mu, axis=1)[:, np.newaxis] - mu if patient_as_input else np.max(mu) - mu\n",
    "    print(\"gap max:\", gap.max())\n",
    "    gap[gap == 0] = 100\n",
    "    print(\"gap min:\", gap.min())\n",
    "    gap = np.min(gap, axis=1 if patient_as_input else 0)\n",
    "    if patient_as_input:\n",
    "        print(\"# contexts with gap_min > 0.001:\", np.sum(gap > 0.001))\n",
    "        print(\"# contexts with gap_min > 0.01:\", np.sum(gap > 0.01))\n",
    "        print(\"# contexts with gap_min > 0.1:\", np.sum(gap > 0.1))\n",
    "        \n",
    "    # remove redundant dimensions\n",
    "    fmat = phi.reshape(-1, d)\n",
    "    U, s, Vt = svd(fmat, full_matrices=False)\n",
    "    sp = np.sum(s > 1e-8)\n",
    "    print(\"[Dim reduction] d={0}, span={1}\".format(d,sp))\n",
    "    s = s[:sp]\n",
    "    U = U[:, :sp]\n",
    "    Vt = Vt[:sp, :]\n",
    "    s = np.diag(s)\n",
    "    U = np.dot(U, s)\n",
    "    M = U.dot(Vt)\n",
    "    rmse = np.sqrt(np.mean(np.abs(M - fmat) ** 2))\n",
    "    print(\"[Dim reduction] Reconstruction rmse: {}\".format(rmse))\n",
    "    new_phi = U.reshape(phi.shape[0], phi.shape[1], sp) if patient_as_input else U\n",
    "    new_theta = Vt.dot(theta)\n",
    "    new_mu = new_phi.dot(new_theta)\n",
    "    mu_rmse = np.sqrt(np.mean(np.abs(mu - new_mu) ** 2))\n",
    "    print(\"[Dim reduction] mu rmse: {}\".format(mu_rmse))\n",
    "\n",
    "    # save\n",
    "    np.savez_compressed('dr_k{0}_d{1}_maxdev{2}.npz'.format(n_drugs, sp, max_dev), features=new_phi, theta=new_theta)\n",
    "    \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = [256, 256]\n",
    "ds = [8, 16, 32, 64]\n",
    "test_size=0.2\n",
    "nets = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "for j in ds:\n",
    "    size = hidden + [j]\n",
    "    print(\"Training NN -- Size {0}\".format(size))\n",
    "    nets[j] = MLPRegressor(hidden_layer_sizes=size, max_iter=500, tol=1e-4, verbose=True).fit(X_train, y_train)\n",
    "    print(\"R^2 full (size {0}): {1}\".format(j, nets[j].score(X, y)))\n",
    "    print(\"R^2 test (size {0}): {1}\".format(j, nets[j].score(X_test, y_test)))\n",
    "    print()\n",
    "    print(\"Saving model...\")\n",
    "    save_model(nets[j])\n",
    "    print()\n",
    "    nets[j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drugs = 175\n",
    "ds = 6\n",
    "\n",
    "res = np.load(\"./representations/dr_k{}_d{}_maxdev0.02.npz\".format((n_drugs,ds)))\n",
    "theta = res[\"theta\"]\n",
    "X = res[\"features\"]\n",
    "features_path = \"../../../DR_Data/epilepsy_signatures_nonbinarized_{}drugs.csv\".format(n_drugs)\n",
    "drug_names = list(pd.read_csv(features_path, index_col=0, header=0).columns)\n",
    "features_path = \"../../../DR_Data/epilepsy_signatures_nonbinarized_10drugs.csv\"\n",
    "drug_names10 = list(pd.read_csv(features_path, index_col=0, header=0).columns)\n",
    "\n",
    "intersect = [d for d in drug_names10 if (d in drug_names)]\n",
    "intersect_ids = [drug_names.index(d) for d in intersect]\n",
    "X = X[intersect_ids,:]\n",
    "np.savez_compressed('dr_k10_d6_maxdev0.02.npz', features=X, theta=theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
